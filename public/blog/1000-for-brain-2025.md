---
title: "Kurzweil’s Prediction - $1000 for a human brain"
date: "2025-09-03"
---

Ray Kurzweil has spent decades making bold predictions about technology's exponential growth. In his 2001 essay ["The Law of Accelerating Returns"](https://www.writingsbyraykurzweil.com/the-law-of-accelerating-returns) he laid out a vision of computing power that would match and surpass human intelligence—complete with specific dates and dollar amounts. Specifically, he predicted that around 2023, a human brain's computing power would be matched by a computer for $1000. This post is my attempt to put Kurzweil’s claim to the test, using the best estimates and hardware benchmarks available right now. Let’s see how close he really got.

Kurzweil’s predictions from The Law of Accelerating Returns

Of course, you can’t literally buy a “human brain” off the shelf for $1,000—at least, not in any sense that captures real thought, consciousness, or experience. The $1,000 brain is a metaphor: it refers to hitting a rough equivalence in raw computational throughput, not replicating the full mystery of intelligence. Brains aren’t just CPUs, and nobody truly knows how to measure every process that matters. Still, as a benchmark for hardware progress, it’s a useful—if imperfect—reference point.

Thanks for reading Josh Bickett's Substack! Subscribe for free to receive new posts and support my work.

**Estimating computation in the human brain**

Kurzweil explained his calculation methodology:

> "My estimate of brain capacity is 100 billion neurons times an average 1,000 connections per neuron (with the calculations taking place primarily in the connections) times 200 calculations per second."

This gives us: 100 billion × 1,000 × 200 = 2 × 10^16 calculations per second. That's 20,000,000,000,000,000 calculations every single second—the figure he used for his prediction.

Kurzweil used "cps" (calculations per second) as a general measure of computational power. Modern AI researchers typically use FLOPS (floating-point operations per second) to measure hardware throughput. For our purposes in this post, I’ll use FLOPS as modern evaluations use this approach—though converting between cps and FLOPS depends heavily on how you model neurons and what computational precision you assume.

_It’s worth noting that in a 2024 WIRED piece, Kurzweil referenced ~10^14 cps “at the level of neurons,” which would put the $1,000 brain much closer to being met by 2023–2025 hardware. Still, for the analysis below, I’m following Joseph Carlsmith’s independent estimate (~10^15 FLOPS), which is widely cited in the AI safety and forecasting community._

The challenge of estimating brain computational capacity is captured well by [Joseph Carlsmith](https://joecarlsmith.com/) at [Open Philanthropy](https://www.openphilanthropy.org/research/how-much-computational-power-does-it-take-to-match-the-human-brain/), who notes:

> "It is reasonably common for people to talk about the brain's computation/task-performance in terms of metrics like FLOP/s. It is much less common for them to say what they mean.

When I first started this project, I thought that there might be some sort of clear and consensus way of understanding this kind of talk that I just hadn't been exposed to. I now think this much less likely."

Despite this fundamental uncertainty, we need a working estimate. Carlsmith's analysis concludes:

> "Overall, I think it more likely than not that 10^15 FLOP/s is enough to perform tasks as well as the human brain."

This is notably lower than Kurzweil's 2 × 10^16 cps estimate, though the units aren't directly comparable. Current brain capacity estimates span an enormous range—from Carlsmith's 10^15 FLOPS up to ~10^18 FLOPS in popular accounts like NIST's estimate of 1 exaflop. The three-order-of-magnitude spread reflects just how little consensus exists on this fundamental question.

Given how much these numbers bounce around, I’m going with Carlsmith’s widely-cited ~10^15 FLOPS estimate, which feels like the best-anchored guess for “brain-equivalent” compute. So that’s our target.

Following Carlsmith's reasoning that synaptic events can be modeled with very low numeric precision (roughly in the 8-bit neighborhood), we will treat FP8 Tensor FLOPS as an acceptable ruler for "brain-equivalent" throughput in this essay. As Carlsmith notes:

> "A standard FLOP is 32 bits, and half-precision is 16 – well in excess of these estimates. Some hardware uses even lower-precision operations, which may come closer. I'd guess that 8 bits would be adequate."

Practically, that means when hardware offers both 16-bit and 8-bit performance figures, I’ll use the 8-bit number as the main estimate.

**Kurzweil’s Prediction**

- We achieve one Human Brain capability for $1,000 around the year 2023.

- We achieve one Human Brain capability for one cent around the year 2037.

- We achieve one Human Race capability for $1,000 around the year 2049.

- We achieve one Human Race capability for one cent around the year 2059.

**How close were we in 2023?**

Since we are approximating a human brain as ~10^15 FLOPS, let’s see how the GPUs stack up.

Based on my research, the best cost-to-compute in 2023 was the NVIDIA RTX 4090, which offered the highest FLOPS-per-dollar of any widely available consumer GPU. At launch, the 4090 retailed for $1,599 and delivered up to ~1.32 × 10^15 8-bit (FP8) FLOPS with 2:4 sparsity enabled, or ~6.6 × 10^14 dense FP8 FLOPS.

Key finding: a single card only clears ~10^15 at 8-bit with 2:4 structured sparsity; dense 8-bit falls short.

Other alternatives, like the A100 or H100 data center GPUs, offered even higher raw throughput but at dramatically higher cost, leading to a worse FLOPS-per-dollar ratio for most buyers. The 4090’s pricing and performance made it the clear cost-to-compute leader for "brain-equivalent" workloads in 2023.

Worth noting: these figures are peak theoretical FLOPS, not sustained application-level throughput, and real-world costs (including power, memory capacity, and system overhead) can differ. Still, for the purposes of this comparison—matching Kurzweil’s $1,000 brain target—the RTX 4090 set the bar for affordable compute in 2023.

At the 2023 MSRP of $1,599 per RTX 4090, the actual distance to Kurzweil's $1,000 target was:

- **1.6×** away if accepting 8-bit with sparsity (single card)

- **3.2×** away if requiring 8-bit without sparsity (two cards)

**2025: Did We Reach the $1,000 Brain?**

By 2025, NVIDIA’s Blackwell generation pushed consumer performance again. A $999 RTX 5080 exists at the sub-$1k price point, and the RTX 5090 (above $1k) delivers roughly 1.7×10^15 at 8-bit + 2:4 sparsity (and ~8.4×10^14 dense). On a per-$1,000 basis, that’s still ~0.84×10^15—about 15–20% short of the ~10^15 target. If prices soften (new or used) or two strong mid-range cards dip under $500 each, the line flips quickly.

**Bottom line**

Kurzweil spoke of achieving brain-equivalent compute for $1,000 “around the year” 2023. I think we’ll hit this target in late 2025 or 2026. My takeaway is that making a bold call in 2001 and landing that close is a remarkable achievement. I’ll be digging into his other predictions with a lot more respect (and a healthy dose of skepticism).

Thanks for reading Josh Bickett's Substack! Subscribe for free to receive new posts and support my work.
